{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9d3399-cc59-4471-b192-7f45fe26f8d8",
   "metadata": {},
   "source": [
    "## <span style=color:blue>Scratch paper related to DM4DS Programming Assignment 2   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54739ab3-0586-4f04-9365-bb0fbcbc1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are boiler plate imports that seem useful\n",
    "# Perhaps cleaner would be to delete or comment out the ones that aren't used in this script...\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "# see https://stackoverflow.com/questions/415511/how-do-i-get-the-current-time-in-python\n",
    "#   for some basics about datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "# sqlalchemy 2.0 documentation: https://www.sqlalchemy.org/\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text as sql_text\n",
    "\n",
    "# the following is deprecated, it seems, so using the sqlalchemy\n",
    "# from pyscopg2 import sqlio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a4b6c-563f-425d-bfa6-bf162f8b4bb7",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Setting up Postgres connection.  Note database name is \"airbnb\" </span>\n",
    "\n",
    "### <span style=color:blue>Note: this should be modified so that the user name/password are not included into the program. </span>\n",
    "\n",
    "<span style=color:blue>E.g., see https://docs.sqlalchemy.org/en/20/core/engines.html for how to construct the URLs that the create_engine command uses.  Also, one should store the user/password into environment variables and read them in to populate the URL.  </span>\n",
    "\n",
    "<span style=color:blue>E.g., see https://stackoverflow.com/questions/4906977/how-can-i-access-environment-variables-in-python for how to work with environment variables on mac, </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c4fe37-23c6-4b4f-9554-26aec6a7b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created db engine.\n"
     ]
    }
   ],
   "source": [
    "# following https://www.geeksforgeeks.org/connecting-postgresql-with-sqlalchemy-in-python/\n",
    "\n",
    "db_eng = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/airbnb',\n",
    "                       connect_args={'options': '-csearch_path={}'.format('new_york_city')},\n",
    "                       isolation_level = 'SERIALIZABLE')\n",
    "#    , echo=True)\n",
    "#    , echo_pool=\"debug\")\n",
    "\n",
    "print(\"Successfully created db engine.\")\n",
    "\n",
    "# connect_args is used to set search_path to 'new_york_city'\n",
    "# isolation_level SERIALIZABLE makes transactions happen in sequence, which is good \n",
    "#      for the benchmarking we will be doing\n",
    "\n",
    "# for general info on sqlalchemy connections,\n",
    "#    see: https://docs.sqlalchemy.org/en/20/core/connections.html\n",
    "\n",
    "# echo from https://docs.sqlalchemy.org/en/20/core/engines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bcf3c-b5d3-40c3-ad4d-6c2df3f27215",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Here is a pattern for using db_eng for queries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c2fb46-6aa3-4905-a056-84612a42b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'sqlalchemy.engine.cursor.CursorResult'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "[('2595', '28794060', datetime.date(2015, 3, 30), '27436102', 'Kellie', 'Jennifer was very good at communicating with us prior to our arrival. Although she could not meet with us herself, she had a friend meet with us to g ... (537 characters truncated) ... or, so we definitely got our workout in going up and down those stairs each day! \\r<br/>\\r<br/>We had a blast! \\r<br/>\\r<br/>Thanks Jennifer! \\r<br/>'),\n",
      " ('2595', '30430122', datetime.date(2015, 4, 21), '6429364', 'Sonya', 'I love this space.  It is truly a gem in the heart of Manhattan.  The location could not be better.  Very clean, comfy, and great warm inviting energy.  Jennifer was very clear and responsive.'),\n",
      " ('2595', '32532759', datetime.date(2015, 5, 19), '12146524', 'Michiel', 'This was our first Airbnb experience, and Jennifer really made it great! No more hotels for us in the future ;) The communication was friendly and she replied very fast. Just great!!')]\n",
      "\n",
      "  listing_id        id        date reviewer_id reviewer_name  \\\n",
      "0       2595  28794060  2015-03-30    27436102        Kellie   \n",
      "1       2595  30430122  2015-04-21     6429364         Sonya   \n",
      "2       2595  32532759  2015-05-19    12146524       Michiel   \n",
      "\n",
      "                                            comments  \n",
      "0  Jennifer was very good at communicating with u...  \n",
      "1  I love this space.  It is truly a gem in the h...  \n",
      "2  This was our first Airbnb experience, and Jenn...  \n",
      "\n",
      "[(28465,)]\n",
      "\n",
      "   count\n",
      "0  28465\n"
     ]
    }
   ],
   "source": [
    "q1 = \"\"\" \n",
    "SELECT *\n",
    "FROM reviews \n",
    "WHERE date >= '2015-01-01' \n",
    "  AND date <= '2015-12-31' \n",
    "\"\"\"\n",
    "q2 = \"\"\" \n",
    "SELECT count(*)\n",
    "FROM reviews \n",
    "WHERE date >= '2015-01-01' \n",
    "  AND date <= '2015-12-31' \n",
    "\"\"\"\n",
    "\n",
    "# you can use conn.execute, which populates a cursor, in this case \"result1\" or \"result2\"\n",
    "# of, you can use pd.read_sql, which populates a dataframe\n",
    "with db_eng.connect() as conn:\n",
    "    result1 = conn.execute(sql_text(q1))   # sql_text was part of import from psycopg2\n",
    "    df1 = pd.read_sql(q1, con=conn)\n",
    "    result2 = conn.execute(sql_text(q2))\n",
    "    df2 = pd.read_sql(q2, con=conn)\n",
    "    # conn.close() is automatically added to the end of this block\n",
    "\n",
    "print()\n",
    "print(type(result1))\n",
    "print()\n",
    "print(type(df1))\n",
    "print()\n",
    "pprint.pp(result1.fetchmany(3), width=120)\n",
    "print()\n",
    "pprint.pp(df1.head(3))\n",
    "print()\n",
    "print(result2.all())            # result is small, so can fetch all of it\n",
    "print()\n",
    "pprint.pp(df2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f4784-d42c-48cd-8882-67f9a481fbfd",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Pattern for creating parameterized functions for creating (parameterized) queries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a06d531-3d80-4508-b266-1ead81bd1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT count(*)\n",
      "FROM reviews\n",
      "WHERE date >= '2015-01-01'\n",
      "  AND date <= '2015-12-31';\n",
      "\n",
      "\n",
      "\n",
      "SELECT DISTINCT l.id \n",
      "FROM listings l, reviews r \n",
      "WHERE l.id = r.listing_id\n",
      "  AND r.date >= '2015-01-01'\n",
      "  AND r.date <= '2015-12-31'\n",
      "ORDER BY l.id;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_query_reviews_count(date1, date2):\n",
    "    q21 = \"\"\"\n",
    "SELECT count(*)\n",
    "FROM reviews\n",
    "WHERE date >= '\"\"\"\n",
    "    q22 = \"\"\"'\n",
    "  AND date <= '\"\"\"\n",
    "    q23 = \"\"\"';\n",
    "\"\"\"\n",
    "    return q21 + date1 + q22 + date2 + q23\n",
    "\n",
    "print(build_query_reviews_count('2015-01-01', '2015-12-31'))\n",
    "\n",
    "def build_query_listings_join_reviews(date1, date2):\n",
    "    q31 = \"\"\"\n",
    "SELECT DISTINCT l.id \n",
    "FROM listings l, reviews r \n",
    "WHERE l.id = r.listing_id\n",
    "  AND r.date >= '\"\"\"\n",
    "    q32 = \"\"\"'\n",
    "  AND r.date <= '\"\"\"\n",
    "    q33 = \"\"\"'\n",
    "ORDER BY l.id;\n",
    "\"\"\"\n",
    "    return q31 + date1 + q32 + date2 + q33\n",
    "\n",
    "print()\n",
    "print(build_query_listings_join_reviews('2015-01-01', '2015-12-31'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5addbb-f68e-409b-ae76-e0695ae36f39",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Here is a pattern for computing the run-time of something, e.g., a query</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a13158-d215-47ed-8582-d90af6b62794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501939\n"
     ]
    }
   ],
   "source": [
    "def time_diff(time1, time2):\n",
    "    return (time2-time1).total_seconds()\n",
    "\n",
    "# testing it:\n",
    "time1 = datetime.now()\n",
    "# put query in place of sleep command\n",
    "time.sleep(0.5)\n",
    "time2 = datetime.now()\n",
    "\n",
    "print(time_diff(time1,time2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce092baf-c301-4e00-b865-a7c563bcc4f0",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Here is a pattern for running a query multiple times, and keeping track of run times</span>\n",
    "\n",
    "<span style=color:blue>This should probably be encapsulated as a parameterized function in a separate python file that is imported for use in either a jupyter notebook or another python program<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49632f1f-a1df-4725-bf23-177fe9168b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am loading the query results into a dataframe to make sure that the full\n",
    "#    value of the query is retrieved by PostgreSQL.  If I retrieve into a\n",
    "#    cursor, then the system may use \"lazy\" evaluation and not actually retrieve\n",
    "#    all the records until I access them later with fetchone() or fetchmany()\n",
    "\n",
    "def run_test(q, count):\n",
    "    time_list = []\n",
    "    for i in range(0,count):\n",
    "        time_start = datetime.now()\n",
    "        # Open new db connection for each execution of the query to avoid multithreading\n",
    "        with db_eng.connect() as conn:\n",
    "            # conn.execute(sql_text(q3))\n",
    "            df = pd.read_sql(q, con=conn)\n",
    "        time_end = datetime.now()\n",
    "        diff = time_diff(time_start, time_end)\n",
    "        time_list.append(diff)\n",
    "    return time_list, \\\n",
    "        round(sum(time_list)/len(time_list), 4), \\\n",
    "        round(min(time_list), 4), \\\n",
    "        round(max(time_list), 4), \\\n",
    "        round(np.std(time_list), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14823a5-d349-44d9-a5ec-06b7f93626a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0859 0.0815 0.0986 0.0043\n"
     ]
    }
   ],
   "source": [
    "q20 = build_reviews_count_query('2015-01-01', '2015-12-31')\n",
    "\n",
    "# don't use \"min\" as a variable name; it will conflict with the name of the built-in function \"min\"\n",
    "time_list, avg, min_number, max_number, std = run_test(q20, 20)\n",
    "# print(time_list)\n",
    "print(avg, min_number, max_number, std)\n",
    "\n",
    "# with an index on date for reviews, average run time is about 0.01 seconds\n",
    "# with no index on date for reviews, average run time is about 0.09 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58fd0e-1fef-4679-982d-11a641c20708",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Here is a pattern for adding/dropping indexes.  Somewhere below I create a function that does this more cleanly.</span>\n",
    "\n",
    "<span style=color:blue>This should probably be encapsulated as a parameterized function in a separate python file that is imported for use in either a jupyter notebook or another python program<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a95fc122-63ea-4cec-9ace-6e5da5d970e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The set of indexes on reviews is: \n",
      "[]\n",
      "\n",
      "The set of indexes on listings is: \n",
      "[('new_york_city', 'listings', 'id_in_listings', None, 'CREATE INDEX id_in_listings ON new_york_city.listings USING btree (id)')]\n"
     ]
    }
   ],
   "source": [
    "q_create_date_in_reviews = '''\n",
    "BEGIN TRANSACTION;\n",
    "CREATE INDEX IF NOT EXISTS date_in_reviews\n",
    "ON reviews(date);\n",
    "END TRANSACTION;\n",
    "'''\n",
    "\n",
    "q_drop_date_in_reviews = '''\n",
    "BEGIN TRANSACTION;\n",
    "DROP INDEX IF EXISTS date_in_reviews;\n",
    "END TRANSACTION;\n",
    "'''\n",
    "q_show_indexes_for_reviews = '''\n",
    "select *\n",
    "from pg_indexes\n",
    "where tablename = 'reviews';\n",
    "'''\n",
    "\n",
    "q_create_id_in_listings = '''\n",
    "BEGIN TRANSACTION;\n",
    "CREATE INDEX IF NOT EXISTS id_in_listings\n",
    "ON listings(id);\n",
    "END TRANSACTION;\n",
    "'''\n",
    "\n",
    "q_drop_id_in_listings = '''\n",
    "BEGIN TRANSACTION;\n",
    "DROP INDEX IF EXISTS id_in_listings;\n",
    "END TRANSACTION;\n",
    "'''\n",
    "q_show_indexes_for_listings = '''\n",
    "select *\n",
    "from pg_indexes\n",
    "where tablename = 'listings';\n",
    "'''\n",
    "\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    # conn.execute(sql_text(q_create_date_in_reviews))\n",
    "    # conn.execute(sql_text(q_drop_date_in_reviews))\n",
    "    conn.execute(sql_text(q_create_id_in_listings))\n",
    "    # conn.execute(sql_text(q_drop_id_in_listings))\n",
    "    result_reviews = conn.execute(sql_text(q_show_indexes_for_reviews))\n",
    "    result_listings = conn.execute(sql_text(q_show_indexes_for_listings))\n",
    "    # print(type(result))\n",
    "    print()\n",
    "    print('The set of indexes on reviews is: ')\n",
    "    print(result_reviews.all())\n",
    "    print()\n",
    "    print('The set of indexes on listings is: ')\n",
    "    print(result_listings.all())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121a925-35ad-44d6-ab9d-9cd8fb9afc26",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Creating a function for creating/dropping an index -- we should probably NOT show this to the students, but rather have them create it</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54e37e96-2499-44d3-a9b8-98ba8f0c8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_drop_index(db_eng, table_name, add_drop, index_name, index_column):\n",
    "    if add_drop == 'add':\n",
    "        q1 = \"\"\"BEGIN TRANSACTION;\n",
    "CREATE INDEX IF NOT EXISTS \"\"\"\n",
    "        q2 = \"\"\"\n",
    "ON \"\"\"\n",
    "        q3 = \"\"\"(\"\"\"\n",
    "        q4 = \"\"\");\n",
    "END TRANSACTION;\n",
    "\"\"\"\n",
    "        modify_index = q1 + index_name + q2 + table_name + q3 + index_column + q4\n",
    "    elif add_drop == 'drop':\n",
    "        q6 = \"\"\"BEGIN TRANSACTION;\n",
    "DROP INDEX IF EXISTS \"\"\"\n",
    "        q7 = \"\"\";\n",
    "END TRANSACTION;\n",
    "\"\"\"\n",
    "        modify_index = q6 + index_name + q7\n",
    "    else:\n",
    "        print('ERROR: call to function add_drop_index has invalid add_drop value:', add_drop)\n",
    "        return\n",
    "\n",
    "    # print('Inside the function add_drop_index the SQL queries produced are: \\n')\n",
    "    # print(modify_index)\n",
    "    # print()\n",
    "\n",
    "    q8 = \"\"\"SELECT *\n",
    "FROM pg_indexes\n",
    "WHERE tablename = '\"\"\"\n",
    "    q9 = \"\"\"';\n",
    "\"\"\"\n",
    "    show_indexes = q8 + table_name + q9\n",
    "\n",
    "    # print(show_indexes)\n",
    "    # print()\n",
    "\n",
    "    with db_eng.connect() as conn:\n",
    "        conn.execute(sql_text(modify_index))\n",
    "        result_indexes = conn.execute(sql_text(show_indexes))\n",
    "\n",
    "    return result_indexes.fetchall()\n",
    "\n",
    "\n",
    "# TESTING\n",
    "\n",
    "# add_test = add_drop_index(db_eng, 'reviews', 'add', 'date_in_reviews', 'date')\n",
    "# print(add_test)\n",
    "\n",
    "# drop_test = add_drop_index(db_eng, 'reviews', 'drop', 'date_in_reviews', '')\n",
    "# print(drop_test)\n",
    "\n",
    "# bad_test = add_drop_index(db_eng, 'reviews', 'foo', 'date_in_reviews', '')\n",
    "# print(bad_test)\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d329b-1d1a-44f3-964e-87681e08f43d",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Setting up a nested dictionary structure so that we can keep track of run times for various queries and updates under various indexing schemes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2169c246-7e5a-4bb1-940c-cc166cc4b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_summary = {}\n",
    "\n",
    "# the key for each entry of perf_dict will be the name of a query or update\n",
    "# the value for each entry of perf_dict will be a \"perf_dict\" of shape (for now)\n",
    "#        { date_in_reviews_N__id_in_listings_N: ...,\n",
    "#          date_in_reviews_N__id_in_listings_Y: ...,\n",
    "#          date_in_reviews_Y__id_in_listings_N: ...,\n",
    "#          date_in_reviews_Y__id_in_listings_Y: ... }\n",
    "\n",
    "# the value for each entry of the inner dict will have be a \"performance profile\" (perf_prof):\n",
    "#       having shape {avg: ..., min: ..., max: ..., std: ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc656698-f5b7-4824-85b5-4047aa67ffb1",
   "metadata": {},
   "source": [
    "### <span style=color:blue>Working towards an example of populating perf_summary with one query; this is some book keeping that will help with adding a value to perf_summary corresponding to all performance results obtained for one query</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc5455f5-3012-4c00-9b16-7af59eb04092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this loop is creating the key values for the \"perf_dict\" values that we will be building\n",
    "#    Probably a cleaner way to do this !!\n",
    "def build_index_description_keys(descriptor_list):  # values will be, ['drop','drop'], ['drop','add'], ['add','drop'], ['add','add']\n",
    "    flag = False\n",
    "    if descriptor_list[0] == 'drop':\n",
    "        prefix = 'date_in_reviews_N'\n",
    "    elif descriptor_list[0] == 'add':\n",
    "        prefix = 'date_in_reviews_Y'\n",
    "    else:\n",
    "        prefix = 'BAD REVIEWS add_drop VALUE: ' + descriptor_list[0]\n",
    "        flag = True\n",
    "    if descriptor_list[1] == 'drop':\n",
    "        suffix = 'id_in_listings_N'\n",
    "    elif descriptor_list[1] == 'add':\n",
    "        suffix = 'id_in_listings_Y'\n",
    "    else:\n",
    "        suffix = 'BAD LISTINGS add_drop VALUE: ' + descriptor_list[1]\n",
    "        flag = True\n",
    "\n",
    "    if not flag:\n",
    "        return prefix + '__' + suffix\n",
    "    else:\n",
    "        return 'ERROR: ' + prefix + '; ' + suffix\n",
    "\n",
    "# TESTING\n",
    "\n",
    "# good1 = build_index_description_keys(['drop','add'])\n",
    "# print(good1)\n",
    "# print()\n",
    "# good2 = build_index_description_keys(['add','drop'])\n",
    "# print(good2)\n",
    "# print()\n",
    "# bad1 = build_index_description_keys(['bad','add'])\n",
    "# print(bad1)\n",
    "# print()\n",
    "# bad2 = build_index_description_keys(['add','bad'])\n",
    "# print(bad2)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def1384-4d12-4e29-9a6c-1d7a59a730b0",
   "metadata": {},
   "source": [
    "<span style=color:blue>Building the query we will do performance testing with</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a80ee9f7-ec02-458b-a7ea-60c5a7600d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT DISTINCT l.id \n",
      "FROM listings l, reviews r \n",
      "WHERE l.id = r.listing_id\n",
      "  AND r.date >= '2015-01-01'\n",
      "  AND r.date <= '2015-12-31'\n",
      "ORDER BY l.id;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_listings_join_reviews_2015 = build_query_listings_join_reviews('2015-01-01', '2015-12-31')\n",
    "\n",
    "print(q_listings_join_reviews_2015)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5faf9d46-7de7-468a-a1f4-0da9dbd88645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'listings_join_reviews_2015': {'date_in_reviews_N__id_in_listings_N': {'avg': 0.1162,\n",
      "                                                                        'min': 0.1077,\n",
      "                                                                        'max': 0.1343,\n",
      "                                                                        'std': 0.0064},\n",
      "                                'date_in_reviews_Y__id_in_listings_N': {'avg': 0.04,\n",
      "                                                                        'min': 0.0357,\n",
      "                                                                        'max': 0.0882,\n",
      "                                                                        'std': 0.0112},\n",
      "                                'date_in_reviews_N__id_in_listings_Y': {'avg': 0.1083,\n",
      "                                                                        'min': 0.105,\n",
      "                                                                        'max': 0.1171,\n",
      "                                                                        'std': 0.0036},\n",
      "                                'date_in_reviews_Y__id_in_listings_Y': {'avg': 0.0369,\n",
      "                                                                        'min': 0.0321,\n",
      "                                                                        'max': 0.0833,\n",
      "                                                                        'std': 0.0116}}}\n"
     ]
    }
   ],
   "source": [
    "# this for loop could be a bit more efficient, but current formulation is easy to understand and imitate\n",
    "\n",
    "perf_dict = {}\n",
    "\n",
    "for spec in [['drop','drop'], ['add','drop'], ['drop','add'], ['add','add']]:\n",
    "    # print('Processing spec: ', str(spec), '\\n')\n",
    "    mod_reviews_index = add_drop_index(db_eng, 'reviews', spec[0], 'date_in_reviews', 'date')\n",
    "    # print(mod_reviews_index)\n",
    "    # print()\n",
    "    mod_listings_index = add_drop_index(db_eng, 'listings', spec[1], 'id_in_listings', 'id')\n",
    "    # print(mod_listings_index)\n",
    "    # print()\n",
    "\n",
    "    time_list, avg, min_number, max_number, std = run_test(q_listings_join_reviews_2015, 20)\n",
    "    perf_profile = {}\n",
    "    perf_profile['avg'] = avg\n",
    "    perf_profile['min'] = min_number\n",
    "    perf_profile['max'] = max_number\n",
    "    perf_profile['std'] = std\n",
    "\n",
    "    key_value = build_index_description_keys(spec)\n",
    "    # print('Value for\"', key_value, '\"is', str(perf_profile))\n",
    "    perf_dict[key_value] = perf_profile\n",
    "\n",
    "perf_summary['listings_join_reviews_2015'] = perf_dict\n",
    "\n",
    "pprint.pp(perf_summary)\n",
    "\n",
    "# print(avg)\n",
    "\n",
    "# with AN index for reviews on date, NO index on id for listings, average run time is about 0.04 seconds\n",
    "# with NO index for reviews on date, NO index on id for listings, average run time is about 0.11 seconds\n",
    "# with AN index for reviews on date, AN index on id for listings, average run time is about 0.033 seconds\n",
    "# with NO index for reviews on date, AN index on id for listings, average run time is about 0.11 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb4335-dd2c-4413-a539-bcc3409fc4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2bf24-6089-4069-85c8-c93fbd65ae80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm4ds",
   "language": "python",
   "name": "dm4ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
